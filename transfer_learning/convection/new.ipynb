{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.optim import LBFGS,Adam\n",
    "from tqdm import tqdm\n",
    "import scipy.io\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# make sure that util is correctly accessed from parent directory\n",
    "ppp_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if ppp_dir not in sys.path:\n",
    "    sys.path.insert(0, ppp_dir)\n",
    "\n",
    "from model.pinn import PINNs\n",
    "from model_parametrized.pinn_ff import PINNff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "CUDA not available, using CPU.\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "# If CUDA is available, print the CUDA version\n",
    "if cuda_available:\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    print(\"CUDA not available, using CPU.\")\n",
    "    device = 'cpu'\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x_range, y_range, x_num, y_num):\n",
    "    x = np.linspace(x_range[0], x_range[1], x_num)\n",
    "    t = np.linspace(y_range[0], y_range[1], y_num)\n",
    "\n",
    "    x_mesh, t_mesh = np.meshgrid(x,t)\n",
    "    data = np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1)\n",
    "    \n",
    "    b_left = data[0,:,:] \n",
    "    b_right = data[-1,:,:]\n",
    "    b_upper = data[:,-1,:]\n",
    "    b_lower = data[:,0,:]\n",
    "    res = data.reshape(-1,2)\n",
    "\n",
    "    return res, b_left, b_right, b_upper, b_lower\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, b_left, b_right, b_upper, b_lower = get_data([0,2*np.pi], [0,1], 101, 101)\n",
    "res_test, _, _, _, _ = get_data([0,2*np.pi], [0,1], 101, 101)\n",
    "\n",
    "res = torch.tensor(res, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_left = torch.tensor(b_left, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_right = torch.tensor(b_right, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_upper = torch.tensor(b_upper, dtype=torch.float32, requires_grad=True).to(device)\n",
    "b_lower = torch.tensor(b_lower, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "x_res, t_res = res[:,0:1], res[:,1:2]\n",
    "x_left, t_left = b_left[:,0:1], b_left[:,1:2]\n",
    "x_right, t_right = b_right[:,0:1], b_right[:,1:2]\n",
    "x_upper, t_upper = b_upper[:,0:1], b_upper[:,1:2]\n",
    "x_lower, t_lower = b_lower[:,0:1], b_lower[:,1:2]\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINNff(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=512, bias=True)\n",
      "    (1): SinAct()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): GELU(approximate='none')\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): GELU(approximate='none')\n",
      "    (6): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "527873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a.almasri\\AppData\\Local\\Temp\\ipykernel_19064\\93869651.py:18: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "# Train PINNs \n",
    "# model = PINNs(in_dim=3, hidden_dim=512, out_dim=1, num_layer=4).to(device)\n",
    "\n",
    "model = PINNff(in_dim=3, \n",
    "                hidden_dim=512,\n",
    "                out_dim=1,\n",
    "                num_layer=4,\n",
    "                init_act_func=\"sin\",\n",
    "                subseq_activ_func=\"gelu\").to(device)\n",
    "\n",
    "model.apply(init_weights)\n",
    "# optim = Adam(model.parameters(), line_search_fn='strong_wolfe')\n",
    "optim = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)\n",
    "print(get_n_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:39<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "model.train() # set to training mode\n",
    "beta = 5\n",
    "beta_tensor1 = torch.full_like(x_res, beta)\n",
    "beta_tensor2 = torch.full_like(x_left, beta)\n",
    "beta_tensor3 = torch.full_like(x_upper, beta)\n",
    "for i in tqdm(range(100)):\n",
    "    total_loss_res = 0.0\n",
    "    total_loss_ic = 0.0\n",
    "    total_loss_bs = 0.0\n",
    "    \n",
    "    pred_res = model(x_res, t_res, beta_tensor1)\n",
    "    pred_left = model(x_left, t_left, beta_tensor2)\n",
    "    pred_right = model(x_right, t_right, beta_tensor2)\n",
    "    pred_upper = model(x_upper, t_upper, beta_tensor3)\n",
    "    pred_lower = model(x_lower, t_lower, beta_tensor3)\n",
    "\n",
    "    u_x = torch.autograd.grad(pred_res, x_res, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(pred_res, t_res, grad_outputs=torch.ones_like(pred_res), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    loss_res = torch.mean((u_t + beta * u_x) ** 2)\n",
    "    loss_bc = torch.mean((pred_upper - pred_lower) ** 2)\n",
    "    loss_ic = torch.mean((pred_left[:,0] - torch.sin(x_left[:,0])) ** 2)\n",
    "\n",
    "    loss_track.append([loss_res.item(), loss_bc.item(), loss_ic.item()])\n",
    "\n",
    "    loss = loss_res + loss_bc + loss_ic\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Res: 0.019235, Loss_BC: 0.035212, Loss_IC: 0.345658\n",
      "Train Loss: 0.400105\n"
     ]
    }
   ],
   "source": [
    "print('Loss Res: {:4f}, Loss_BC: {:4f}, Loss_IC: {:4f}'.format(loss_track[-1][0], loss_track[-1][1], loss_track[-1][2]))\n",
    "print('Train Loss: {:4f}'.format(np.sum(loss_track[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\".\")  # Base directory for results\n",
    "images_dir = base_dir / \"images\"  # Subdirectory for images\n",
    "weights_dir = base_dir / \"weights\"  # Subdirectory for stored model\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "images_dir.mkdir(parents=True, exist_ok=True)\n",
    "weights_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_solution(x, t, beta):\n",
    "    return torch.sin(x - beta *t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_and_errors(rho_values, predictions, analytical_solutions, errors, num_cols=4, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot predictions and errors for multiple rho values in a grid layout.\n",
    "\n",
    "    Args:\n",
    "        rho_values (list): List of rho values.\n",
    "        predictions (dict): Dictionary of predictions for each rho value.\n",
    "        analytical_solutions (dict): Dictionary of analytical solutions for each rho value.\n",
    "        errors (dict): Dictionary of absolute errors for each rho value.\n",
    "        num_cols (int): Number of columns in the grid (default: 4).\n",
    "        save_path (str or Path, optional): Path to save the figure. If None, the figure is not saved.\n",
    "    \"\"\"\n",
    "    num_rho = len(rho_values)\n",
    "    num_rows = 2  # Fixed: Row 1 for predictions, Row 2 for errors\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(4 * num_cols, 6))\n",
    "\n",
    "    # Ensure axes is a 2D array even if num_cols == 1\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    for idx, rho in enumerate(rho_values):\n",
    "        col = idx % num_cols\n",
    "\n",
    "        # Extract data for the current rho\n",
    "        pred = predictions[rho]\n",
    "        analytical = analytical_solutions[rho]\n",
    "        abs_error = errors[rho]\n",
    "        percentage_error = (abs_error / np.maximum(analytical, 1e-8)) * 100  # Avoid division by zero\n",
    "\n",
    "        ax_pred = axes[0, col]\n",
    "        ax_pred.plot(pred, label=\"Prediction\", color=\"blue\", linewidth=2)\n",
    "        ax_pred.plot(analytical, label=\"Analytical\", color=\"orange\", linestyle=\"dashed\", linewidth=2)\n",
    "        ax_pred.set_title(f\"Rho: {rho} - Prediction\")\n",
    "        ax_pred.set_xlabel(\"t - Time\")  # Horizontal axis label\n",
    "        ax_pred.set_ylabel(\"u(t) - Value\")  # Vertical axis label\n",
    "        ax_pred.legend()\n",
    "        \n",
    "\n",
    "        # Plot absolute and percentage errors (Row 2)\n",
    "        ax_err = axes[1, col]\n",
    "        #ax_err.plot(abs_error, label=\"Absolute Error\", color=\"red\", linewidth=2)\n",
    "        ax_err.plot(percentage_error, label=\"Percentage Error\", color=\"green\", linestyle=\"dotted\", linewidth=2)\n",
    "        ax_err.set_title(f\"Rho: {rho} - Relative Error (%)\")\n",
    "        ax_err.set_xlabel(\"t - Time\")  # Horizontal axis label\n",
    "        ax_err.set_ylabel(\"delta u(t) (%)\")  # Vertical axis label\n",
    "        ax_err.legend()\n",
    "\n",
    "    # Hide unused subplots if num_rho < num_cols\n",
    "    for idx in range(num_rho, num_cols):\n",
    "        axes[0, idx].axis(\"off\")\n",
    "        axes[1, idx].axis(\"off\")\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure if a save path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        print(f\"Figure saved to {save_path}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_parameter_range(rho_values, dataset, model):\n",
    "    predictions = {}\n",
    "    analytical_solutions = {}\n",
    "    errors = {}\n",
    "\n",
    "    for rho in rho_values:\n",
    "        # Get test points for the current rho\n",
    "        x_test, t_test, _ = dataset.get_test_points(rho)\n",
    "        rho_test = torch.full_like(x_test, rho).to(device)\n",
    "\n",
    "        # Compute analytical solution\n",
    "        u_analytical = analytical_solution(x_test, t_test, rho).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "        # Compute best model predictions\n",
    "        with torch.no_grad():\n",
    "            pred = model(x_test.to(device), t_test.to(device), rho_test.to(device))[:, 0:1]\n",
    "            pred = pred.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "        # Compute error\n",
    "        error = np.abs(u_analytical - pred)\n",
    "\n",
    "        # Store results\n",
    "        predictions[rho] = pred\n",
    "        analytical_solutions[rho] = u_analytical\n",
    "        errors[rho] = error\n",
    "\n",
    "    return predictions, analytical_solutions, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model.eval()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m predictions, analytical_solutions, errors = test_on_parameter_range([\u001b[32m50\u001b[39m], \u001b[43mdataset\u001b[49m, best_model)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Plot predictions and errors\u001b[39;00m\n\u001b[32m      5\u001b[39m plot_predictions_and_errors(\n\u001b[32m      6\u001b[39m     rho_values=[\u001b[32m50\u001b[39m],\n\u001b[32m      7\u001b[39m     predictions=predictions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     save_path=images_dir / \u001b[33m\"\u001b[39m\u001b[33mpredictions_and_errors.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions, analytical_solutions, errors = test_on_parameter_range([50], dataset, best_model)\n",
    "\n",
    "# Plot predictions and errors\n",
    "plot_predictions_and_errors(\n",
    "    rho_values=[50],\n",
    "    predictions=predictions,\n",
    "    analytical_solutions=analytical_solutions,\n",
    "    errors=errors,\n",
    "    num_cols=4,\n",
    "    save_path=images_dir / \"predictions_and_errors.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
