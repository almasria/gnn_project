{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import random\n",
    "from torch.optim import LBFGS, Adam\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "# make sure that util is correctly accessed from parent directory\n",
    "ppp_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if ppp_dir not in sys.path:\n",
    "    sys.path.insert(0, ppp_dir)\n",
    "\n",
    "from util import *\n",
    "from model_parametrized.pinnsformer_parametrized import PINNsformer_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "# If CUDA is available, print the CUDA version\n",
    "if cuda_available:\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds and configure cuda device\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDEData(Dataset):\n",
    "    def __init__(self, x_range, t_range, rho_values, x_points, t_points):\n",
    "        \"\"\"\n",
    "        Initialize the dataset for PDE data with multiple rho values.\n",
    "\n",
    "        Args:\n",
    "            x_range (list): Spatial domain [x_min, x_max].\n",
    "            t_range (list): Temporal domain [t_min, t_max].\n",
    "            rho_values (list): List of rho values for different scenarios.\n",
    "            x_points (int): Number of points in the spatial domain.\n",
    "            t_points (int): Number of points in the temporal domain.\n",
    "            device (str): Device to store the tensors ('cpu' or 'cuda').\n",
    "        \"\"\"\n",
    "        self.device = \"cpu\"\n",
    "        self.x_range = x_range\n",
    "        self.t_range = t_range\n",
    "        self.rho_values = rho_values  # Store multiple rho values\n",
    "        self.x_points = x_points\n",
    "        self.t_points = t_points\n",
    "        \n",
    "        # Generate the data for all rho values\n",
    "        self.data = {}\n",
    "        for rho in rho_values:\n",
    "            res, b_left, b_right, b_upper, b_lower = self._generate_data()\n",
    "            \n",
    "            # Convert boundary points to PyTorch tensors\n",
    "            b_left = torch.tensor(b_left, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "            b_right = torch.tensor(b_right, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "            b_upper = torch.tensor(b_upper, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "            b_lower = torch.tensor(b_lower, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "            \n",
    "            self.data[rho] = {\n",
    "                'res': torch.tensor(res, dtype=torch.float32, requires_grad=True).to(self.device),\n",
    "                'b_left': b_left,\n",
    "                'b_right': b_right,\n",
    "                'b_upper': b_upper,\n",
    "                'b_lower': b_lower,\n",
    "                # Precompute analytical solutions for boundary points\n",
    "                'u_left': self.analytical_solution(b_left[:, 0:1], b_left[:, 1:2], rho),\n",
    "                'u_right': self.analytical_solution(b_right[:, 0:1], b_right[:, 1:2], rho),\n",
    "                'u_upper': self.analytical_solution(b_upper[:, 0:1], b_upper[:, 1:2], rho),\n",
    "                'u_lower': self.analytical_solution(b_lower[:, 0:1], b_lower[:, 1:2], rho),\n",
    "            }\n",
    "    \n",
    "    def _generate_data(self):\n",
    "        \"\"\"\n",
    "        Generate the interior and boundary points for the PDE.\n",
    "\n",
    "        Returns:\n",
    "            res (np.ndarray): Interior points.\n",
    "            b_left, b_right, b_upper, b_lower (np.ndarray): Boundary points.\n",
    "        \"\"\"\n",
    "        x = np.linspace(self.x_range[0], self.x_range[1], self.x_points)\n",
    "        t = np.linspace(self.t_range[0], self.t_range[1], self.t_points)\n",
    "        \n",
    "        x_mesh, t_mesh = np.meshgrid(x, t)\n",
    "        data = np.concatenate((np.expand_dims(x_mesh, -1), np.expand_dims(t_mesh, -1)), axis=-1)\n",
    "        \n",
    "        b_left = data[0, :, :] \n",
    "        b_right = data[-1, :, :]\n",
    "        b_upper = data[:, -1, :]\n",
    "        b_lower = data[:, 0, :]\n",
    "        res = data.reshape(-1, 2)\n",
    "\n",
    "        return res, b_left, b_right, b_upper, b_lower\n",
    "    \n",
    "    def analytical_solution(self, x, t, rho):\n",
    "        \"\"\"\n",
    "        Compute the analytical solution u_ana(x, t, rho).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Spatial points.\n",
    "            t (torch.Tensor): Temporal points.\n",
    "            rho (float): Reaction coefficient.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Analytical solution u(x, t, rho).\n",
    "        \"\"\"\n",
    "        return torch.sin(x - rho*t)\n",
    "    \n",
    "    def get_interior_points(self, rho):\n",
    "        \"\"\"\n",
    "        Get the interior points (x_res, t_res, rho_res) for a specific rho.\n",
    "\n",
    "        Args:\n",
    "            rho (float): The rho value for the current scenario.\n",
    "\n",
    "        Returns:\n",
    "            x_res, t_res, rho_res (torch.Tensor): Interior points with rho values.\n",
    "        \"\"\"\n",
    "        res = self.data[rho]['res']\n",
    "        x_res, t_res = res[:, 0:1], res[:, 1:2]\n",
    "        rho_res = torch.full_like(x_res, rho)  # Same shape, constant rho\n",
    "        return x_res, t_res, rho_res\n",
    "    \n",
    "    def get_boundary_points(self, rho):\n",
    "        \"\"\"\n",
    "        Get the boundary points (x_left, t_left, etc.) for a specific rho.\n",
    "\n",
    "        Args:\n",
    "            rho (float): The rho value for the current scenario.\n",
    "\n",
    "        Returns:\n",
    "            Boundary points (torch.Tensor): x, t, and rho values for all boundaries.\n",
    "        \"\"\"\n",
    "        b_left = self.data[rho]['b_left']\n",
    "        b_right = self.data[rho]['b_right']\n",
    "        b_upper = self.data[rho]['b_upper']\n",
    "        b_lower = self.data[rho]['b_lower']\n",
    "        \n",
    "        x_left, t_left = b_left[:, 0:1], b_left[:, 1:2]\n",
    "        x_right, t_right = b_right[:, 0:1], b_right[:, 1:2]\n",
    "        x_upper, t_upper = b_upper[:, 0:1], b_upper[:, 1:2]\n",
    "        x_lower, t_lower = b_lower[:, 0:1], b_lower[:, 1:2]\n",
    "        \n",
    "        rho_left = torch.full_like(x_left, rho)\n",
    "        rho_right = torch.full_like(x_right, rho)\n",
    "        rho_upper = torch.full_like(x_upper, rho)\n",
    "        rho_lower = torch.full_like(x_lower, rho)\n",
    "        \n",
    "        return x_left, t_left, rho_left, x_right, t_right, rho_right, x_upper, t_upper, rho_upper, x_lower, t_lower, rho_lower\n",
    "    \n",
    "    def get_boundary_values(self, rho):\n",
    "        \"\"\"\n",
    "        Get the precomputed analytical solutions for the boundary points.\n",
    "\n",
    "        Args:\n",
    "            rho (float): The rho value for the current scenario.\n",
    "\n",
    "        Returns:\n",
    "            u_left, u_right, u_upper, u_lower (torch.Tensor): Analytical solutions at the boundaries.\n",
    "        \"\"\"\n",
    "        return (self.data[rho]['u_left'], self.data[rho]['u_right'], \n",
    "                self.data[rho]['u_upper'], self.data[rho]['u_lower'])\n",
    "    \n",
    "    def get_test_points(self, rho):\n",
    "        \"\"\"\n",
    "        Get the test points (res_test) and their spatial and temporal components for a specific rho.\n",
    "\n",
    "        Args:\n",
    "            rho (float): The rho value for the current scenario.\n",
    "\n",
    "        Returns:\n",
    "            res_test (torch.Tensor): Test points as a tensor.\n",
    "            x_test, t_test, rho_test (torch.Tensor): Spatial, temporal, and rho components of the test points.\n",
    "        \"\"\"\n",
    "        res_test = self.data[rho]['res']\n",
    "        x_test, t_test = res_test[:, 0:1], res_test[:, 1:2]\n",
    "        rho_test = torch.full_like(x_test, rho)  # Same shape, constant rho\n",
    "        return res_test, x_test, t_test, rho_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Configuration parameters and wandb logging\n",
    "total_i = 20\n",
    "model_name = \"pinnsformer_params\"\n",
    "config_dict = {\n",
    "    \"total_i\": total_i,\n",
    "    \"model\": model_name,\n",
    "    \"d_out\": 1,\n",
    "    \"d_model\": 32,\n",
    "    \"d_hidden\": 512,\n",
    "    \"N\": 1,\n",
    "    \"heads\": 2,\n",
    "    \"bias_fill\": 0.01,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"batch_size\": 128,\n",
    "    \"learning_rate\": 1e-3\n",
    "}\n",
    "'''\n",
    "run = wandb.init(\n",
    "    project=\"pinnsformer\",\n",
    "    config=config_dict,\n",
    "    settings=wandb.Settings(silent=True)\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Weight initialization function\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(config_dict[\"bias_fill\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PINNsformer_params(\n",
    "    d_out=config_dict[\"d_out\"],\n",
    "    d_model=config_dict[\"d_model\"],\n",
    "    d_hidden=config_dict[\"d_hidden\"],\n",
    "    N=config_dict[\"N\"],\n",
    "    heads=config_dict[\"heads\"]\n",
    ").to(device)\n",
    "\n",
    "## model.apply(init_weights)\n",
    "if config_dict[\"optimizer\"] == \"LBFGS\":\n",
    "    optim = LBFGS(model.parameters(), line_search_fn='strong_wolfe')\n",
    "elif config_dict[\"optimizer\"] == \"adam\":\n",
    "    optim = Adam(model.parameters(), lr=config_dict[\"learning_rate\"])\n",
    "\n",
    "print(model)\n",
    "print(get_n_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_values = [50.0]\n",
    "dataset = PDEData(x_range=[0, 2 * np.pi], t_range=[0, 1], rho_values=rho_values, x_points=101, t_points=101)\n",
    "total_i = config_dict[\"total_i\"]\n",
    "loss_track = {i: {} for i in range(total_i)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config_dict[\"optimizer\"] == \"LBFGS\":\n",
    "    for i in tqdm(range(total_i)):\n",
    "        for rho in rho_values:\n",
    "            def closure():\n",
    "                # Get interior points\n",
    "                x_res, t_res, rho_res = dataset.get_interior_points(rho)\n",
    "                # Get boundary points and their analytical values\n",
    "                x_left, t_left, rho_left, x_right, t_right, rho_right, x_upper, t_upper, rho_upper, x_lower, t_lower, rho_lower = dataset.get_boundary_points(rho)\n",
    "                u_left, u_right, u_upper, u_lower = dataset.get_boundary_values(rho)\n",
    "                \n",
    "                # Model predictions for interior and boundary points\n",
    "                pred_res = model(x_res, t_res, rho_res)\n",
    "                pred_left = model(x_left, t_left, rho_left)\n",
    "                pred_right = model(x_right, t_right, rho_right)\n",
    "                pred_upper = model(x_upper, t_upper, rho_upper)\n",
    "                pred_lower = model(x_lower, t_lower, rho_lower)\n",
    "\n",
    "                # Compute derivatives with respect to space and time\n",
    "                u_x = torch.autograd.grad(pred_res, x_res, grad_outputs=torch.ones_like(pred_res),\n",
    "                                            retain_graph=True, create_graph=True)[0]\n",
    "                u_t = torch.autograd.grad(pred_res, t_res, grad_outputs=torch.ones_like(pred_res),\n",
    "                                            retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "                # Define the loss terms:\n",
    "                # PDE residual loss (here we assume u_t - rho * u * (1-u) = 0, adjust as needed)\n",
    "                loss_res = torch.mean((u_t + rho * u_x) ** 2)\n",
    "                # Boundary condition loss (e.g., matching the solution at t=t_min vs t=t_max)\n",
    "                loss_bc = torch.mean((pred_upper - pred_lower) ** 2)\n",
    "                # Initial condition loss (here comparing the left boundary with the analytical solution)\n",
    "                loss_ic = torch.mean((pred_left[:,0] - torch.sin(x_left[:,0])) ** 2)\n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "\n",
    "                loss = loss_res + loss_bc + loss_ic\n",
    "                '''\n",
    "                wandb.log({\n",
    "                    \"loss\": loss.item(),\n",
    "                    \"loss_res\": loss_res.item(),\n",
    "                    \"loss_bc\": loss_bc.item(),\n",
    "                    \"loss_ic\": loss_ic.item(),\n",
    "                    \"iteration\": i,\n",
    "                    \"rho\": rho\n",
    "                })\n",
    "                '''\n",
    "                # Track losses in a dictionary\n",
    "                if rho not in loss_track[i]:\n",
    "                    loss_track[i][rho] = {}\n",
    "                loss_track[i][rho][\"loss_res\"] = loss_res.item()\n",
    "                loss_track[i][rho][\"loss_bc\"] = loss_bc.item()\n",
    "                loss_track[i][rho][\"loss_ic\"] = loss_ic.item()\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss.backward(retain_graph=True)\n",
    "                return loss\n",
    "\n",
    "            optim.step(closure)\n",
    "\n",
    "    #wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rho values\n",
    "rho_values = [50.0]\n",
    "total_i = config_dict[\"total_i\"]\n",
    "\n",
    "# Create the dataset\n",
    "dataset = PDEData(x_range=[0, 2 * torch.pi], t_range=[0, 1], rho_values=rho_values, x_points=101, t_points=101)\n",
    "\n",
    "# Training loop\n",
    "loss_track = {i: {} for i in range(total_i)}  # Initialize a dictionary for tracking losses\n",
    "\n",
    "for i in tqdm(range(total_i)):\n",
    "    total_loss_res = 0.0\n",
    "    total_loss_bc = 0.0\n",
    "    total_loss_ic = 0.0\n",
    "    num_batches = 0  # Track the number of batches\n",
    "\n",
    "    for rho in rho_values:\n",
    "        # Get interior points and create a mini-batch DataLoader\n",
    "        x_res, t_res, rho_res = dataset.get_interior_points(rho)\n",
    "        interior_dataset = TensorDataset(x_res, t_res, rho_res)\n",
    "        interior_loader = DataLoader(interior_dataset, batch_size=config_dict[\"batch_size\"], shuffle=True)\n",
    "\n",
    "        # Get full boundary data for current rho\n",
    "        (x_left, t_left, rho_left,\n",
    "         x_right, t_right, rho_right,\n",
    "         x_upper, t_upper, rho_upper,\n",
    "         x_lower, t_lower, rho_lower) = dataset.get_boundary_points(rho)\n",
    "        u_left, u_right, u_upper, u_lower = dataset.get_boundary_values(rho)\n",
    "\n",
    "        for bx, bt, brho in interior_loader:\n",
    "            # Ensure mini-batch inputs require gradients for differentiation\n",
    "            bx.requires_grad_()\n",
    "            bt.requires_grad_()\n",
    "\n",
    "            # Forward pass on interior mini-batch\n",
    "            pred_res = model(bx, bt, brho)\n",
    "            # Compute derivative with respect to time and space\n",
    "\n",
    "            u_t = torch.autograd.grad(pred_res, bt, \n",
    "                                       grad_outputs=torch.ones_like(pred_res),\n",
    "                                       retain_graph=True,\n",
    "                                       create_graph=True)[0]\n",
    "            \n",
    "            u_x = torch.autograd.grad(pred_res, bx, \n",
    "                                       grad_outputs=torch.ones_like(pred_res),\n",
    "                                       retain_graph=True,\n",
    "                                       create_graph=True)[0]\n",
    "\n",
    "\n",
    "            # Compute residual loss\n",
    "            loss_res = torch.mean((u_t + rho * u_x) ** 2)\n",
    "\n",
    "\n",
    "            # Forward pass on full-boundary data\n",
    "            pred_left  = model(x_left, t_left, rho_left)\n",
    "            pred_right = model(x_right, t_right, rho_right)\n",
    "            pred_upper = model(x_upper, t_upper, rho_upper)\n",
    "            pred_lower = model(x_lower, t_lower, rho_lower)\n",
    "\n",
    "            \n",
    "            # Compute boundary condition loss\n",
    "            loss_bc = torch.mean((pred_upper - pred_lower) ** 2)\n",
    "\n",
    "\n",
    "            # Compute initial condition loss\n",
    "            loss_ic = torch.mean((pred_left[:,0] - torch.sin(x_left[:,0])) ** 2)\n",
    "\n",
    "\n",
    "            # Total loss\n",
    "            loss = loss_res + loss_bc + loss_ic\n",
    "\n",
    "            # Accumulate losses for averaging\n",
    "            total_loss_res += loss_res.item()\n",
    "            total_loss_bc += loss_bc.item()\n",
    "            total_loss_ic += loss_ic.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            optim.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optim.step()\n",
    "\n",
    "        # Compute average losses\n",
    "        avg_loss_res = total_loss_res / num_batches\n",
    "        avg_loss_bc = total_loss_bc / num_batches\n",
    "        avg_loss_ic = total_loss_ic / num_batches\n",
    "        avg_total_loss = avg_loss_res + avg_loss_bc + avg_loss_ic\n",
    "        '''\n",
    "        # Log average losses at the end of the iteration\n",
    "        wandb.log({\n",
    "            \"iteration\": i,\n",
    "            \"avg_loss_res\": avg_loss_res,\n",
    "            \"avg_loss_bc\": avg_loss_bc,\n",
    "            \"avg_loss_ic\": avg_loss_ic,\n",
    "            \"avg_total_loss\": avg_total_loss\n",
    "        })\n",
    "        '''\n",
    "        # Track average losses in a dictionary\n",
    "        loss_track[i][rho] = {\n",
    "            \"loss_res\": avg_loss_res,\n",
    "            \"loss_bc\": avg_loss_bc,\n",
    "            \"loss_ic\": avg_loss_ic\n",
    "        }\n",
    "\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\".\")\n",
    "images_dir = base_dir / \"images\"\n",
    "weights_dir = base_dir / \"weights\"\n",
    "images_dir.mkdir(parents=True, exist_ok=True)\n",
    "weights_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final losses for each rho value\n",
    "last_iteration = total_i - 1\n",
    "for rho in rho_values:\n",
    "    print('Rho: {:4f}, Loss Res: {:4f}, Loss BC: {:4f}, Loss IC: {:4f}'.format(\n",
    "        rho,\n",
    "        loss_track[last_iteration][rho][\"loss_res\"],\n",
    "        loss_track[last_iteration][rho][\"loss_bc\"],\n",
    "        loss_track[last_iteration][rho][\"loss_ic\"]\n",
    "    ))\n",
    "    total_loss = (loss_track[last_iteration][rho][\"loss_res\"] +\n",
    "                  loss_track[last_iteration][rho][\"loss_bc\"] +\n",
    "                  loss_track[last_iteration][rho][\"loss_ic\"])\n",
    "    print('Train Loss: {:4f}'.format(total_loss))\n",
    "\n",
    "model_path = weights_dir / \"1d_reaction_pinnsformer_extended.pt\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "errors = []\n",
    "for rho in rho_values:\n",
    "    res_test, x_test, t_test, rho_test = dataset.get_test_points(rho)\n",
    "    u_analytical = dataset.analytical_solution(x_test, t_test, rho).cpu().detach().numpy().reshape(101, 101)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x_test.to(device), t_test.to(device), rho_test.to(device))[:, 0:1]\n",
    "        pred = pred.cpu().detach().numpy().reshape(101, 101)\n",
    "\n",
    "    rl1 = np.sum(np.abs(u_analytical - pred)) / np.sum(np.abs(u_analytical))\n",
    "    rl2 = np.sqrt(np.sum((u_analytical - pred)**2) / np.sum(u_analytical**2))\n",
    "    print(f\"Rho: {rho}, Relative L1 error: {rl1:.4f}, Relative L2 error: {rl2:.4f}\")\n",
    "    errors.append((rho, rl1, rl2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Visualization\n",
    "for rho in rho_values:\n",
    "    res_test, x_test, t_test, rho_test = dataset.get_test_points(rho)\n",
    "    u_analytical = dataset.analytical_solution(x_test, t_test, rho).cpu().detach().numpy().reshape(101, 101)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x_test.to(device), t_test.to(device), rho_test.to(device))[:, 0:1]\n",
    "        pred = pred.cpu().detach().numpy().reshape(101, 101)\n",
    "    abs_error = np.abs(u_analytical - pred)\n",
    "\n",
    "    # Plot predicted solution\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(pred, extent=[0, 2 * np.pi, 1, 0], aspect='auto')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('t')\n",
    "    plt.title(f'Predicted u(x,t) for rho={rho}')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plot_path = images_dir / f\"1d_convection_pinnsformer_pred_rho-{rho}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot analytical solution\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(u_analytical, extent=[0, 2 * np.pi, 1, 0], aspect='auto')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('t')\n",
    "    plt.title(f'Exact u(x,t) for rho={rho}')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plot_path = images_dir / f\"1d_convection_pinnsformer_exact_rho-{rho}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot absolute error\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(abs_error, extent=[0, 2 * np.pi, 1, 0], aspect='auto')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('t')\n",
    "    plt.title(f'Absolute Error for rho={rho}')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plot_path = images_dir / f\"1d_convection_pinnsformer_error_rho-{rho}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning Visualizations\n",
    "rho_transfer=[4.5,5.5,6.5,7.5]\n",
    "\n",
    "dataset = PDEData(x_range=[0, 2 * np.pi], t_range=[0, 1], rho_values=rho_transfer, x_points=101, t_points=101)\n",
    "\n",
    "for rho in rho_transfer:\n",
    "    res_test, x_test, t_test, rho_test = dataset.get_test_points(rho)\n",
    "    u_analytical = dataset.analytical_solution(x_test, t_test, rho).cpu().detach().numpy().reshape(101, 101)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x_test.to(device), t_test.to(device), rho_test.to(device))[:, 0:1]\n",
    "        pred = pred.cpu().detach().numpy().reshape(101, 101)\n",
    "    abs_error = np.abs(u_analytical - pred)\n",
    "\n",
    "    # Plot predicted solution\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(pred, extent=[0, 2 * np.pi, 1, 0], aspect='auto')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('t')\n",
    "    plt.title(f'Predicted u(x,t) for rho={rho}')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plot_path = images_dir / f\"1d_reaction_pinnsformer_pred_rho-{rho}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot analytical solution\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(u_analytical, extent=[0, 2 * np.pi, 1, 0], aspect='auto')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('t')\n",
    "    plt.title(f'Exact u(x,t) for rho={rho}')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plot_path = images_dir / f\"1d_reaction_pinnsformer_exact_rho-{rho}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot absolute error\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.imshow(abs_error, extent=[0, 2 * np.pi, 1, 0], aspect='auto')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('t')\n",
    "    plt.title(f'Absolute Error for rho={rho}')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plot_path = images_dir / f\"1d_reaction_pinnsformer_error_rho-{rho}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
